{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-ctgan",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport random\nfrom ctgan import CTGAN\nimport shap\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\nimport seaborn as sns\n\n#==================================Part 1==============================================================\n# Load sample dataset and train CTGAN\n\nseed_df = pd.read_csv('sample_with_3_percent_fraud.csv')\nprint(\"Sample dataset shape:\", seed_df.shape)\nprint(\"Sample fraud rate:\", seed_df['isFraud'].mean())\n\n# Train CTGAN\ncat_cols = ['type','nameOrig','nameDest']\nctgan = CTGAN(epochs=150, batch_size=1000)\nctgan.fit(seed_df, discrete_columns=cat_cols)\n\n# Generate 100,000 synthetic transactions\nsyn = ctgan.sample(100000)\nprint(\"\\nSynthetic dataset shape:\", syn.shape)\nprint(\"Synthetic fraud rate:\", syn['isFraud'].mean())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geolocation-rules",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Part 2==============================================================\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Assign random lat/lon per account\n",
    "loc_o = {acc: (random.uniform(-90,90), random.uniform(-180,180))\n",
    "         for acc in syn['nameOrig'].unique()}\n",
    "loc_d = {acc: (random.uniform(-90,90), random.uniform(-180,180))\n",
    "         for acc in syn['nameDest'].unique()}\n",
    "syn['locOrig'] = syn['nameOrig'].map(loc_o)\n",
    "syn['locDest'] = syn['nameDest'].map(loc_d)\n",
    "\n",
    "\n",
    "#==================================Part 3==============================================================\n",
    "def apply_rules(df):\n",
    "    \"\"\"Apply 7 fraud detection rules.\"\"\"\n",
    "    for i in range(1,8):\n",
    "        df[f'rule{i}']=0\n",
    "    history = {}\n",
    "    df.sort_values(['nameOrig','step'], inplace=True)\n",
    "    for idx,row in df.iterrows():\n",
    "        acct = row['nameOrig']\n",
    "        amt, tp, dest, ts = row['amount'], row['type'], row['nameDest'], row['step']\n",
    "        loc1, loc2 = row['locOrig'], row['locDest']\n",
    "        if acct not in history:\n",
    "            history[acct] = {'times':[], 'dests':set(), 'type_amts':{}}\n",
    "        h = history[acct]\n",
    "        if amt>50000: df.at[idx,'rule1']=1\n",
    "        recent = [t for t in h['times'] if ts-t<=1]\n",
    "        if len(recent)>=5: df.at[idx,'rule2']=1\n",
    "        if (ts%24)<5: df.at[idx,'rule3']=1\n",
    "        if (tp=='CASH_OUT' and amt<10) or (tp=='TRANSFER' and amt>80000):\n",
    "            df.at[idx,'rule4']=1\n",
    "        if dest not in h['dests']: df.at[idx,'rule5']=1\n",
    "        if geodesic(loc1, loc2).km>500: df.at[idx,'rule6']=1\n",
    "        lst = h['type_amts'].get(tp,[])\n",
    "        if len(lst)>=10:\n",
    "            mu, sd = np.mean(lst), np.std(lst)\n",
    "            if abs(amt-mu)>3*sd: df.at[idx,'rule7']=1\n",
    "        h['times'].append(ts)\n",
    "        h['dests'].add(dest)\n",
    "        h['type_amts'].setdefault(tp,[]).append(amt)\n",
    "    # Use consistent column name (BUG FIX - was isFlaggedFraud_rules)\n",
    "    df['isFlaggedFraud'] = df[[f'rule{i}' for i in range(1,8)]].max(axis=1)\n",
    "    return df\n",
    "\n",
    "syn = apply_rules(syn)\n",
    "print(syn[['rule1','rule2','rule3','rule4','rule5','rule6','rule7','isFlaggedFraud']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Part 4==============================================================\n",
    "# Data Preprocessing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "model_df = syn.drop(columns=['locOrig','locDest']+[f'rule{i}' for i in range(1,8)])\n",
    "\n",
    "# Save label encoders (BUG FIX)\n",
    "label_encoders = {}\n",
    "for col in ['type','nameOrig','nameDest']:\n",
    "    le = LabelEncoder()\n",
    "    model_df[col] = le.fit_transform(model_df[col])\n",
    "    label_encoders[col] = le\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "print(\"Label encoders saved\")\n",
    "\n",
    "# Keep isFlaggedFraud as feature (BUG FIX)\n",
    "X = model_df.drop(columns=['isFraud'])\n",
    "y = model_df['isFraud']\n",
    "print(\"Features:\", X.columns.tolist())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit scaler on training data only (BUG FIX)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"Scaler saved\")\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_tr_bal, y_tr_bal = sm.fit_resample(X_train_scaled, y_train)\n",
    "y_tr_bal = y_tr_bal.astype(int)\n",
    "print(\"Post-SMOTE fraud rate:\", y_tr_bal.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "models",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Part 5==============================================================\n",
    "# Train Models\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Autoencoder\n",
    "X_norm = X_tr_bal[y_tr_bal==0]\n",
    "inp_dim = X_norm.shape[1]\n",
    "\n",
    "inp = layers.Input(shape=(inp_dim,))\n",
    "e = layers.Dense(inp_dim//2, activation='relu')(inp)\n",
    "e = layers.Dense(inp_dim//4, activation='relu')(e)\n",
    "d = layers.Dense(inp_dim//2, activation='relu')(e)\n",
    "out = layers.Dense(inp_dim, activation='sigmoid')(d)\n",
    "\n",
    "ae = models.Model(inp, out)\n",
    "ae.compile(optimizer='adam', loss='mse')\n",
    "ae.fit(X_norm, X_norm, epochs=30, batch_size=256, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Random Forest\n",
    "X_train_df = pd.DataFrame(X_tr_bal, columns=X.columns)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_df, y_tr_bal)\n",
    "print(\"Models trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Part 6==============================================================\n",
    "# Ensemble Optimization\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "p_rf = rf.predict_proba(X_test_scaled)[:,1]\n",
    "recon = ae.predict(X_test_scaled)\n",
    "err = np.mean((recon - X_test_scaled)**2, axis=1)\n",
    "p_ae = (err - err.min()) / (err.max() - err.min())\n",
    "\n",
    "best = {'f1':0}\n",
    "for alpha in np.linspace(0,1,11):\n",
    "    score = alpha*p_rf + (1-alpha)*p_ae\n",
    "    prec, recs, th = precision_recall_curve(y_test, score)\n",
    "    f1s = 2*prec*recs/(prec+recs+1e-8)\n",
    "    idx = np.nanargmax(f1s)\n",
    "    if f1s[idx] > best['f1']:\n",
    "        best = {'alpha':alpha, 'threshold':th[idx], 'f1':f1s[idx]}\n",
    "\n",
    "print(f\"Best alpha: {best['alpha']}\")\n",
    "print(f\"Best threshold: {best['threshold']}\")\n",
    "print(f\"Best F1: {best['f1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Part 7==============================================================\n",
    "# Save Models (BUG FIX - save actual trained models)\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump({'best_alpha': best['alpha'], 'best_thresh': best['threshold']}, 'thresholds.pkl')\n",
    "joblib.dump(rf, 'rf_model.pkl')  # Save actual trained rf (BUG FIX)\n",
    "ae.save('ae_model.keras')\n",
    "\n",
    "print(\"All models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Part 8==============================================================\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "alpha, thr = best['alpha'], best['threshold']\n",
    "final_score = alpha*p_rf + (1-alpha)*p_ae\n",
    "y_pred = (final_score >= thr).astype(int)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-score:  {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"AUC-ROC:   {roc_auc_score(y_test, final_score):.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualizations",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Part 9==============================================================\n",
    "# Visualizations\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title(\"Confusion Matrix\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, final_score)\n",
    "axes[1].plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, final_score):.2f}\")\n",
    "axes[1].plot([0, 1], [0, 1], 'k--')\n",
    "axes[1].set_title(\"ROC Curve\")\n",
    "axes[1].set_xlabel(\"False Positive Rate\")\n",
    "axes[1].set_ylabel(\"True Positive Rate\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, final_score)\n",
    "axes[2].plot(recall, precision)\n",
    "axes[2].set_title(\"Precision-Recall Curve\")\n",
    "axes[2].set_xlabel(\"Recall\")\n",
    "axes[2].set_ylabel(\"Precision\")\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shap",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Part 10==============================================================\n",
    "# SHAP Analysis\n",
    "\n",
    "X_sample = pd.DataFrame(X_test, columns=X.columns).sample(n=min(200, len(X_test)), random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_vals = explainer.shap_values(X_sample)\n",
    "\n",
    "print(\"X_sample shape:\", X_sample.shape)\n",
    "shap_vals_reduced = shap_vals[:, :, 0]\n",
    "shap.summary_plot(shap_vals_reduced, X_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}